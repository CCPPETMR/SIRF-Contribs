{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sirf.STIR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-938b0326558e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msirf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTIR\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msirf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUtilities\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexamples_data_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sirf.STIR"
     ]
    }
   ],
   "source": [
    "#%% Initial imports etc\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '15'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import sirf.STIR as pet\n",
    "\n",
    "from sirf.Utilities import examples_data_path\n",
    "from ccpi.optimisation.algorithms import CGLS, PDHG, FISTA\n",
    "from ccpi.optimisation.operators import BlockOperator, LinearOperator\n",
    "from ccpi.optimisation.functions import KullbackLeibler, IndicatorBox, \\\n",
    "         FunctionOperatorComposition, BlockFunction, MixedL21Norm , ZeroFunction, KullbackLeibler\n",
    "from ccpi.framework import ImageData\n",
    "from ccpi.plugins.regularisers import FGP_TV, FGP_dTV\n",
    "setattr(FGP_TV, 'convex_conjugate', lambda self,x: 0.0)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports for plotting\n",
    "from __future__ import print_function, division\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy\n",
    "\n",
    "def display_slice(container, direction, title, cmap, minmax, size, axis_labels):\n",
    "    \n",
    "        \n",
    "    def get_slice_3D(x):\n",
    "        \n",
    "        if direction == 0:\n",
    "            img = container[x]\n",
    "            x_lim = container.shape[2]\n",
    "            y_lim = container.shape[1]\n",
    "            x_label = axis_labels[2]\n",
    "            y_label = axis_labels[1] \n",
    "            \n",
    "        elif direction == 1:\n",
    "            img = container[:,x,:]\n",
    "            x_lim = container.shape[2]\n",
    "            y_lim = container.shape[0] \n",
    "            x_label = axis_labels[2]\n",
    "            y_label = axis_labels[0]             \n",
    "            \n",
    "        elif direction == 2:\n",
    "            img = container[:,:,x]\n",
    "            x_lim = container.shape[1]\n",
    "            y_lim = container.shape[0]    \n",
    "            x_label = axis_labels[1]\n",
    "            y_label = axis_labels[0]             \n",
    "        \n",
    "        if size is None:\n",
    "            fig = plt.figure()\n",
    "        else:\n",
    "            fig = plt.figure(figsize=size)\n",
    "        \n",
    "        if isinstance(title, (list, tuple)):\n",
    "            dtitle = title[x]\n",
    "        else:\n",
    "            dtitle = title\n",
    "        \n",
    "        gs = gridspec.GridSpec(1, 2, figure=fig, width_ratios=(1,.05), height_ratios=(1,))\n",
    "        # image\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "      \n",
    "        ax.set_xlabel(x_label)     \n",
    "        ax.set_ylabel(y_label)\n",
    " \n",
    "        aximg = ax.imshow(img, cmap=cmap, origin='upper', extent=(0,x_lim,y_lim,0))\n",
    "        aximg.set_clim(minmax)\n",
    "        ax.set_title(dtitle + \" {}\".format(x))\n",
    "        # colorbar\n",
    "        ax = fig.add_subplot(gs[0, 1])\n",
    "        plt.colorbar(aximg, cax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.show(fig)\n",
    "        \n",
    "    return get_slice_3D\n",
    "\n",
    "    \n",
    "def islicer(data, direction, title=\"\", slice_number=None, cmap='gray', minmax=None, size=None, axis_labels=None):\n",
    "\n",
    "    '''Creates an interactive integer slider that slices a 3D volume along direction\n",
    "    \n",
    "    :param data: DataContainer or numpy array\n",
    "    :param direction: slice direction, int, should be 0,1,2 or the axis label\n",
    "    :param title: optional title for the display\n",
    "    :slice_number: int start slice number, optional. If None defaults to center slice\n",
    "    :param cmap: matplotlib color map\n",
    "    :param minmax: colorbar min and max values, defaults to min max of container\n",
    "    :param size: int or tuple specifying the figure size in inch. If int it specifies the width and scales the height keeping the standard matplotlib aspect ratio \n",
    "    '''\n",
    "    \n",
    "    if axis_labels is None:\n",
    "        if hasattr(data, \"dimension_labels\"):\n",
    "            axis_labels = [data.dimension_labels[0],data.dimension_labels[1],data.dimension_labels[2]]\n",
    "        else:\n",
    "            axis_labels = ['X', 'Y', 'Z']\n",
    "\n",
    "    \n",
    "    if hasattr(data, \"as_array\"):\n",
    "        container = data.as_array()\n",
    "        \n",
    "        if not isinstance (direction, int):\n",
    "            if direction in data.dimension_labels.values():\n",
    "                direction = data.get_dimension_axis(direction)                             \n",
    "\n",
    "    elif isinstance (data, numpy.ndarray):\n",
    "        container = data\n",
    "        \n",
    "    if slice_number is None:\n",
    "        slice_number = int(data.shape[direction]/2)\n",
    "        \n",
    "    slider = widgets.IntSlider(min=0, max=data.shape[direction]-1, step=1, \n",
    "                             value=slice_number, continuous_update=False, description=axis_labels[direction])\n",
    "\n",
    "    if minmax is None:\n",
    "        amax = container.max()\n",
    "        amin = container.min()\n",
    "    else:\n",
    "        amin = min(minmax)\n",
    "        amax = max(minmax)\n",
    "    \n",
    "    if isinstance (size, (int, float)):\n",
    "        default_ratio = 6./8.\n",
    "        size = ( size , size * default_ratio )\n",
    "    \n",
    "    interact(display_slice(container, \n",
    "                           direction, \n",
    "                           title=title, \n",
    "                           cmap=cmap, \n",
    "                           minmax=(amin, amax),\n",
    "                           size=size, axis_labels=axis_labels),\n",
    "             x=slider);\n",
    "    \n",
    "    return slider\n",
    "    \n",
    "\n",
    "def link_islicer(*args):\n",
    "    '''links islicers IntSlider widgets'''\n",
    "    linked = [(widg, 'value') for widg in args]\n",
    "    # link pair-wise\n",
    "    pairs = [(linked[i+1],linked[i]) for i in range(len(linked)-1)]\n",
    "    for pair in pairs:\n",
    "        widgets.link(*pair)\n",
    "\n",
    "def psnr(img1, img2, data_range=1):\n",
    "    mse = numpy.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 1000\n",
    "    return 20 * numpy.log10(data_range / numpy.sqrt(mse))\n",
    "\n",
    "\n",
    "def plotter2D(datacontainers, titles=None, fix_range=False, stretch_y=False, cmap='gray', axis_labels=None):\n",
    "    '''plotter2D(datacontainers=[], titles=[], fix_range=False, stretch_y=False, cmap='gray', axes_labels=['X','Y'])\n",
    "    \n",
    "    plots 1 or more 2D plots in an (n x 2) matix\n",
    "    multiple datasets can be passed as a list\n",
    "    \n",
    "    Can take ImageData, AquistionData or numpy.ndarray as input\n",
    "    '''\n",
    "    if(isinstance(datacontainers, list)) is False:\n",
    "        datacontainers = [datacontainers]\n",
    "\n",
    "    if titles is not None:\n",
    "        if(isinstance(titles, list)) is False:\n",
    "            titles = [titles]\n",
    "            \n",
    "\n",
    "    \n",
    "    nplots = len(datacontainers)\n",
    "    rows = int(round((nplots+0.5)/2.0))\n",
    "\n",
    "    fig, (ax) = plt.subplots(rows, 2,figsize=(15,15))\n",
    "\n",
    "    axes = ax.flatten() \n",
    "\n",
    "    range_min = float(\"inf\")\n",
    "    range_max = 0\n",
    "    \n",
    "    if fix_range == True:\n",
    "        for i in range(nplots):\n",
    "            if type(datacontainers[i]) is numpy.ndarray:\n",
    "                dc = datacontainers[i]\n",
    "            else:\n",
    "                dc = datacontainers[i].as_array()\n",
    "                \n",
    "            range_min = min(range_min, numpy.amin(dc))\n",
    "            range_max = max(range_max, numpy.amax(dc))\n",
    "        \n",
    "    for i in range(rows*2):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    for i in range(nplots):\n",
    "        axes[i].set_visible(True)\n",
    "        \n",
    "        if titles is not None:\n",
    "            axes[i].set_title(titles[i])\n",
    "       \n",
    "        if axis_labels is not None:\n",
    "            axes[i].set_ylabel(axis_labels[1])\n",
    "            axes[i].set_xlabel(axis_labels[0]) \n",
    "            \n",
    "        if type(datacontainers[i]) is numpy.ndarray:\n",
    "            dc = datacontainers[i]          \n",
    "        else:\n",
    "            dc = datacontainers[i].as_array()\n",
    "            \n",
    "            if axis_labels is None:\n",
    "                axes[i].set_ylabel(datacontainers[i].dimension_labels[0])\n",
    "                axes[i].set_xlabel(datacontainers[i].dimension_labels[1])        \n",
    "        \n",
    "        \n",
    "        sp = axes[i].imshow(dc, cmap=cmap, origin='upper', extent=(0,dc.shape[1],dc.shape[0],0))\n",
    "    \n",
    "        \n",
    "        im_ratio = dc.shape[0]/dc.shape[1]\n",
    "        \n",
    "        if stretch_y ==True:   \n",
    "            axes[i].set_aspect(1/im_ratio)\n",
    "            im_ratio = 1\n",
    "            \n",
    "        plt.colorbar(sp, ax=axes[i],fraction=0.0467*im_ratio, pad=0.02)\n",
    "        \n",
    "        if fix_range == True:\n",
    "            sp.set_clim(range_min,range_max) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kullback Leibler methods with numba\n",
    "try:\n",
    "    import numba\n",
    "    from numba import jit, prange\n",
    "    import numpy\n",
    "    from numpy import sqrt, log, inf\n",
    "    has_numba = True\n",
    "    '''Some parallelisation of KL calls'''\n",
    "    @jit(nopython=True)\n",
    "    def kl_proximal(x,b, bnoise, tau, out):\n",
    "            for i in prange(x.size):\n",
    "                out.flat[i] = 0.5 *  ( \n",
    "                    ( x.flat[i] - bnoise.flat[i] - tau ) +\\\n",
    "                    numpy.sqrt( (x.flat[i] + bnoise.flat[i] - tau)**2. + \\\n",
    "                        (4. * tau * b.flat[i]) \n",
    "                    )\n",
    "                )\n",
    "    @jit(nopython=True)\n",
    "    def kl_proximal_conjugate(x, b, bnoise, tau, out):\n",
    "        #z = x + tau * self.bnoise\n",
    "        #return 0.5*((z + 1) - ((z-1)**2 + 4 * tau * self.b).sqrt())\n",
    "\n",
    "        for i in prange(x.size):\n",
    "            z = x.flat[i] + ( tau * bnoise.flat[i] )\n",
    "            out.flat[i] = 0.5 * ( \n",
    "                (z + 1) - numpy.sqrt((z-1)*(z-1) + 4 * tau * b.flat[i])\n",
    "                )\n",
    "    @jit(nopython=True)\n",
    "    def kl_gradient(x, b, bnoise, out):\n",
    "        for i in prange(x.size):\n",
    "            out.flat[i] = 1 - b.flat[i]/(x.flat[i] + bnoise.flat[i])\n",
    "\n",
    "    @jit(nopython=True)\n",
    "    def kl_div(x, y, out):\n",
    "        for i in prange(x.size):\n",
    "            X = x.flat[i]\n",
    "            Y = y.flat[i]    \n",
    "            if x.flat[i] > 0 and y.flat[i] > 0:\n",
    "                out.flat[i] = X * numpy.log(X/Y) - X + Y\n",
    "            elif X == 0 and Y >= 0:\n",
    "                out.flat[i] = Y\n",
    "            else:\n",
    "                out.flat[i] = numpy.inf\n",
    "    \n",
    "    # force a jit\n",
    "    x = numpy.asarray(numpy.random.random((10,10)), dtype=numpy.float32)\n",
    "    b = numpy.asarray(numpy.random.random((10,10)), dtype=numpy.float32)\n",
    "    bnoise = numpy.zeros_like(x)\n",
    "    out = numpy.empty_like(x)\n",
    "    tau = 1.\n",
    "    kl_div(b,x,out)\n",
    "    kl_gradient(x,b,bnoise,out)\n",
    "    kl_proximal(x,b, bnoise, tau, out)\n",
    "    kl_proximal_conjugate(x,b, bnoise, tau, out)\n",
    "\n",
    "except ImportError as ie:\n",
    "    has_numba = False\n",
    "\n",
    "class ChangeSign(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_instance(class_name, *args,**kwargs):\n",
    "        \n",
    "        setattr(class_name, '__call__', ChangeSign.KL_call)\n",
    "        setattr(class_name, 'gradient', ChangeSign.KL_gradient)\n",
    "        setattr(class_name, 'proximal_conjugate', ChangeSign.KL_proximal_conjugate)\n",
    "        \n",
    "        instance = class_name(*args, **kwargs)\n",
    "        # swap the original set_acquisition_data with a modified one\n",
    "        set_acquisition_data_sirf = instance.set_acquisition_data\n",
    "        setattr(class_name, 'set_acquisition_data_sirf', set_acquisition_data_sirf)\n",
    "        setattr(class_name, 'set_acquisition_data', ChangeSign.set_acquisition_data)\n",
    "        \n",
    "        # return the new instance\n",
    "        return instance\n",
    "\n",
    "    ### Few fixes for common interface\n",
    "    @staticmethod\n",
    "    def set_acquisition_data(self, ad):\n",
    "        #save a reference to acquisition_data in the class\n",
    "        self.b = ad\n",
    "        self.set_acquisition_data_sirf(ad)\n",
    "        \n",
    "    @staticmethod\n",
    "    def KL_call(self, x):\n",
    "        return - self.get_value(x)\n",
    "    @staticmethod\n",
    "    def KL_gradient(self, image, subset = -1, out = None):\n",
    "\n",
    "        assert_validity(image, pet.ImageData)\n",
    "        grad = pet.ImageData()\n",
    "        grad.handle = pystir.cSTIR_objectiveFunctionGradient\\\n",
    "            (self.handle, image.handle, subset)\n",
    "        check_status(grad.handle)\n",
    "        # change sign\n",
    "        #grad*=-1\n",
    "        if out is None:\n",
    "            return -1 * grad  \n",
    "        else:\n",
    "            out.fill(-1 * grad)\n",
    "    @staticmethod\n",
    "    def KL_proximal_conjugate(self, x, tau, out=None):\n",
    "\n",
    "        r'''Proximal operator of the convex conjugate of KullbackLeibler at x:\n",
    "\n",
    "           .. math::     prox_{\\tau * f^{*}}(x)\n",
    "        '''\n",
    "        \n",
    "        self.bnoise = x * 0.\n",
    "        if has_numba:\n",
    "            if out is None:\n",
    "                out = (x * 0.)\n",
    "                out_np = out.as_array()\n",
    "                kl_proximal_conjugate(x.as_array(), self.b.as_array(), self.bnoise.as_array(), tau, out_np)\n",
    "                out.fill(out_np)\n",
    "                return out\n",
    "            else:\n",
    "                out_np = out.as_array()\n",
    "                kl_proximal_conjugate(x.as_array(), self.b.as_array(), self.bnoise.as_array(), tau, out_np)\n",
    "                out.fill(out_np)                    \n",
    "        else:\n",
    "            if out is None:\n",
    "                z = x + tau * self.bnoise\n",
    "                return 0.5*((z + 1) - ((z-1)**2 + 4 * tau * self.b).sqrt())\n",
    "            else:\n",
    "                \n",
    "                tmp = tau * self.bnoise\n",
    "                tmp += x\n",
    "                tmp -= 1\n",
    "                \n",
    "                self.b.multiply(4*tau, out=out)    \n",
    "                \n",
    "                out.add(tmp.power(2), out=out)\n",
    "                out.sqrt(out=out)\n",
    "                out *= -1\n",
    "                tmp += 2\n",
    "                out += tmp\n",
    "                out *= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of emission: (127, 150, 150)\n",
      "applying attenuation (please wait, may take a while)...\n"
     ]
    }
   ],
   "source": [
    "# Define norm for the acquisition model\n",
    "def norm(self, **kwargs):\n",
    "    return LinearOperator.PowerMethod(self, kwargs.get('iterations',10))[0]\n",
    "\n",
    "setattr(pet.AcquisitionModelUsingRayTracingMatrix, 'norm', norm)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#% go to directory with input files\n",
    "\n",
    "EXAMPLE = 'SIMULATION'\n",
    "\n",
    "\n",
    "if EXAMPLE == 'SIMULATION':\n",
    "    data_dir = os.path.abspath('/home/edo/GitHub/PETMR/sympdata')\n",
    "    os.chdir(data_dir)\n",
    "    ##%% copy files to working folder and change directory to where the output files are\n",
    "    new_dir = os.path.abspath(os.path.join(data_dir, 'CIL-numba'))\n",
    "    \n",
    "    # adapt this path to your situation (or start everything in the relevant directory)\n",
    "    #os.chdir('/mnt/data/CCPPETMR/201909_hackathon/Simulations/PET/SimulationData')\n",
    "    #shutil.rmtree(new_dir,True)\n",
    "    if not os.path.exists(new_dir):\n",
    "        shutil.copytree(data_dir,new_dir)\n",
    "    os.chdir(new_dir)\n",
    "    \n",
    "    ground_truth = 'FDG_small.hv'\n",
    "    attenuation_header = 'uMap_small.hv'\n",
    "    image_header = attenuation_header\n",
    "    sinogram_header = 'FDG_sino_noisy.hs'\n",
    "\n",
    "image = pet.ImageData(image_header);\n",
    "image_array=image.as_array()\n",
    "mu_map = pet.ImageData(attenuation_header);\n",
    "mu_map_array=mu_map.as_array();\n",
    "\n",
    "# Show Emission image\n",
    "print('Size of emission: {}'.format(image.shape))\n",
    "\n",
    "\n",
    "#%%\n",
    "sinogram = pet.AcquisitionData(sinogram_header)\n",
    "# rebin the data to speed up\n",
    "sinogram = sinogram.rebin(11)\n",
    "\n",
    "# attenuation\n",
    "attn_acq_model = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "asm_attn = pet.AcquisitionSensitivityModel(mu_map, attn_acq_model)\n",
    "# converting attenuation into attenuation factors (see previous exercise)\n",
    "asm_attn.set_up(sinogram)\n",
    "attn_factors = pet.AcquisitionData(sinogram)\n",
    "attn_factors.fill(1.0)\n",
    "print('applying attenuation (please wait, may take a while)...')\n",
    "asm_attn.unnormalise(attn_factors)\n",
    "# use these in the final attenuation model\n",
    "asm_attn = pet.AcquisitionSensitivityModel(attn_factors)\n",
    "\n",
    "am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "# we will increate the number of rays used for every Line-of-Response (LOR) as an example\n",
    "# (it is not required for the exercise of course)\n",
    "am.set_num_tangential_LORs(5)\n",
    "am.set_acquisition_sensitivity(asm_attn)\n",
    "\n",
    "# this seems to use a lot of memory! 256 Gb went!\n",
    "# pet.AcquisitionData.set_storage_scheme('memory')\n",
    "am.set_up(sinogram,image)\n",
    "\n",
    "#% simulate some data using forward projection\n",
    "if EXAMPLE == 'SIMULATION':\n",
    "    \n",
    "    acquired_data = sinogram\n",
    "    image.fill(1)\n",
    "    noisy_data = acquired_data.clone()\n",
    "\n",
    "# Show util per iteration\n",
    "def show_data(it, obj, x):\n",
    "    plt.imshow(x.as_array()[0])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating operator norm\n",
      "done\n",
      "PDHG setting up\n",
      "PDHG configured\n",
      "     Iter   Max Iter     Time/Iter            Objective\n",
      "                               [s]                     \n",
      "        0        500         0.000          9.16145e+06\n",
      "        2        500        12.171          3.57824e+06\n"
     ]
    }
   ],
   "source": [
    "#%% TV reconstruction using algorithm below\n",
    "\n",
    "alpha = 0\n",
    "\n",
    "\n",
    "method = 'implicit'\n",
    "\n",
    "if method == 'explicit':\n",
    "\n",
    "    # Create operators\n",
    "    op1 = GradientSIRF(image) \n",
    "    op2 = am\n",
    "\n",
    "    # Create BlockOperator\n",
    "    operator = BlockOperator(op1, op2, shape=(2,1) ) \n",
    "\n",
    "    f2 = KullbackLeibler(noisy_data)  \n",
    "    g =  IndicatorBox(lower=0)    \n",
    "\n",
    "    f1 = alpha * MixedL21Norm() \n",
    "    f = BlockFunction(f1, f2)  \n",
    "    normK = operator.norm()\n",
    "\n",
    "elif method == 'implicit':\n",
    "\n",
    "    operator = am      \n",
    "    # refdata, regularisation_parameter, iterations, tolerance, eta_const, methodTV, nonneg, device\n",
    "    #g = FGP_dTV(mu_map, alpha, 500, 1e-7, 1e-2, 0, 1, 'gpu' )\n",
    "    #g = FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' ) \n",
    "    # f = KullbackLeibler(noisy_data)\n",
    "    if alpha == 0:\n",
    "        g = IndicatorBox(lower=0)\n",
    "    else:\n",
    "        g = FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' )\n",
    "\n",
    "#         fidelity = pet.PoissonLogLikelihoodWithLinearModelForMeanAndProjData()\n",
    "\n",
    "    fidelity = ChangeSign.get_instance(pet.PoissonLogLikelihoodWithLinearModelForMeanAndProjData)  \n",
    "    fidelity.set_acquisition_model(am)\n",
    "    fidelity.set_acquisition_data(noisy_data)\n",
    "    fidelity.set_num_subsets(4)\n",
    "    fidelity.set_up(image)\n",
    "    fidelity.L = 1e4\n",
    "    print (\"Calculating operator norm\")\n",
    "    normK = operator.norm(iterations=5)\n",
    "    print (\"done\")\n",
    "\n",
    "sigma = 100.\n",
    "tau = 1/(sigma*normK**2)\n",
    "tau = 1. / normK\n",
    "sigma = 1. / normK\n",
    "\n",
    "# Setup and run the PDHG algorithm\n",
    "def sirf_update_objective(self):\n",
    "\n",
    "    p1 = self.f((self.x)) + self.g(self.x)\n",
    "    #d1 = -(self.f.convex_conjugate(self.y) + self.g.convex_conjugate(-1*self.operator.adjoint(self.y)))\n",
    "    #p1 = 0.\n",
    "    #d1 = 0.\n",
    "    #self.loss.append([p1, d1, p1-d1])\n",
    "    self.loss.append(p1)\n",
    "\n",
    "setattr(PDHG, 'update_objective', sirf_update_objective )\n",
    "algo = PDHG(f = fidelity, g = g, operator = operator, tau = tau, sigma = sigma)\n",
    "algo.max_iteration = 500\n",
    "algo.update_objective_interval = 2\n",
    "algo.run(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OSMAPOSL reconstruction\n",
    "#fidelity_sirf = pet.make_Poisson_loglikelihood(noisy_data)\n",
    "# fidelity_sirf = pet.PoissonLogLikelihoodWithLinearModelForMeanAndProjData()\n",
    "\n",
    "# #fidelity_sirf??\n",
    "# fidelity_sirf.set_acquisition_model(am)\n",
    "# fidelity_sirf.set_acquisition_data(noisy_data)\n",
    "# fidelity_sirf.set_num_subsets(4)\n",
    "# fidelity_sirf.set_up(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_image = pet.ImageData(ground_truth)\n",
    "reconstructed_image = ground_truth_image.allocate(1)\n",
    "recon = pet.OSMAPOSLReconstructor()\n",
    "recon.set_objective_function(fidelity)\n",
    "recon.set_num_subsets(1)\n",
    "num_iters=10;\n",
    "recon.set_num_subiterations(num_iters)\n",
    "#recon.set_input(noisy_data)\n",
    "recon.set_up(reconstructed_image)\n",
    "recon.reconstruct(reconstructed_image)\n",
    "\n",
    "islicer(ground_truth_image, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 285, 285)\n"
     ]
    }
   ],
   "source": [
    "# load MR data for dTV\n",
    "refdata = pet.ImageData('T2.hv')\n",
    "print (refdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### how to find a proper alpha\n",
    "alpha = 5e-3\n",
    "obj = []\n",
    "r_iterations = 500\n",
    "r_alpha = alpha\n",
    "r_tolerance = 1e-7\n",
    "r_eta_const = 1e-2\n",
    "r_iso = 0\n",
    "r_nonneg = 1\n",
    "#FGP_dTV(refdata, r_alpha, r_iterations, r_tolerance, r_eta_const, r_iso, r_nonneg, device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00553003608753365\n",
      "(127, 150, 150)\n"
     ]
    }
   ],
   "source": [
    "print (tau)\n",
    "print (algo.get_output().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDHG setting up\n",
      "PDHG configured\n",
      "     Iter   Max Iter     Time/Iter            Objective\n",
      "                               [s]                     \n",
      "        0        500         0.000          9.16145e+06\n",
      "       10        500        14.124          3.57980e+06\n",
      "       20        500        13.598          1.43798e+06\n",
      "       30        500        12.554          1.52704e+06\n",
      "       40        500        11.740          1.62166e+06\n",
      "       50        500        11.582          1.60829e+06\n",
      "       60        500        11.695          1.43776e+06\n",
      "       70        500        11.212          1.36896e+06\n",
      "       80        500        11.580          1.36988e+06\n",
      "       90        500        11.737          1.37458e+06\n",
      "      100        500        11.468          1.38151e+06\n",
      "      110        500        11.373          1.36226e+06\n",
      "      120        500        11.815          1.35911e+06\n",
      "      130        500        11.772          1.35196e+06\n",
      "      140        500        11.901          1.35066e+06\n",
      "      150        500        11.710          1.35249e+06\n",
      "      160        500        11.846          1.35008e+06\n",
      "      170        500        11.557          1.34908e+06\n",
      "      180        500        11.626          1.34855e+06\n",
      "      190        500        11.549          1.34758e+06\n",
      "      200        500        11.769          1.34729e+06\n",
      "      210        500        11.625          1.34706e+06\n",
      "      220        500        11.592          1.34677e+06\n",
      "      230        500        11.602          1.34626e+06\n",
      "      240        500        11.847          1.34570e+06\n",
      "      250        500        11.669          1.34577e+06\n",
      "      260        500        11.609          1.34626e+06\n",
      "      270        500        11.786          1.34675e+06\n"
     ]
    }
   ],
   "source": [
    "# reset algo and run 500 iterations\n",
    "# it should take 86.107 s/iter * 500 iter / 3600 s/h = 11.9 h\n",
    "alphas = [ r_alpha, r_alpha] #, 0.,]\n",
    "gs = [ FGP_dTV(refdata, r_alpha, r_iterations, r_tolerance, r_eta_const, r_iso, r_nonneg, device='gpu'), \n",
    "      FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' )]#, IndicatorBox(lower=0.)]\n",
    "regul = ['FGP_dTV', 'FGP_TV', 'IndicatorBox']\n",
    "algos = []\n",
    "for alpha, g, reg in zip(alphas, gs, regul):\n",
    "    algo = PDHG(f = fidelity, g = g, operator = operator, tau = tau, sigma = sigma)\n",
    "    algo.max_iteration = 500\n",
    "    algo.update_objective_interval = 10\n",
    "\n",
    "    if False:\n",
    "        run = 10\n",
    "        for i in range(algo.max_iteration / run):\n",
    "            algo.run(run)\n",
    "            # saves to os.getcwd()\n",
    "            #print (os.getcwd())\n",
    "            fname = os.path.join(os.getcwd(),\"PDHG_{}_alpha{}_iter_{}\".format(reg,alpha,algo.iteration))\n",
    "            algo.get_output().write(fname)\n",
    "    else:\n",
    "        def save_output(iteration,obj,x):\n",
    "            int_alpha = '1e-2'\n",
    "            fname = os.path.join(os.getcwd(),\"PDHG_{}_alpha{}_iter_{}\".format(reg,int_alpha,iteration))\n",
    "            #print (fname)\n",
    "            x.write(fname)\n",
    "\n",
    "        algo.run(500,callback=save_output,verbose=True)\n",
    "        #algos.append(algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fidelity_sirf = pet.PoissonLogLikelihoodWithLinearModelForMeanAndProjData()\n",
    "\n",
    "# fidelity_sirf??\n",
    "# fidelity_sirf.set_acquisition_model(am)\n",
    "# fidelity_sirf.set_acquisition_data(noisy_data)\n",
    "# fidelity_sirf.set_num_subsets(1)\n",
    "# fidelity_sirf.set_up(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-fe1d6f9b6cfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregul\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0malgos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregul\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "reg = regul[0]\n",
    "algos[0].run()\n",
    "\n",
    "reg = regul[1]\n",
    "algos[1].run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
