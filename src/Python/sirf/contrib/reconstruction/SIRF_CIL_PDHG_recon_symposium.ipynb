{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Initial imports etc\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '15'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import sirf.STIR as pet\n",
    "\n",
    "from sirf.Utilities import examples_data_path\n",
    "from ccpi.optimisation.algorithms import CGLS, PDHG, FISTA\n",
    "from ccpi.optimisation.operators import BlockOperator, LinearOperator\n",
    "from ccpi.optimisation.functions import KullbackLeibler, IndicatorBox, \\\n",
    "         FunctionOperatorComposition, BlockFunction, MixedL21Norm , ZeroFunction, KullbackLeibler\n",
    "from ccpi.framework import ImageData\n",
    "from ccpi.plugins.regularisers import FGP_TV, FGP_dTV\n",
    "setattr(FGP_TV, 'convex_conjugate', lambda self,x: 0.0)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports for plotting\n",
    "from __future__ import print_function, division\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy\n",
    "\n",
    "def display_slice(container, direction, title, cmap, minmax, size, axis_labels):\n",
    "    \n",
    "        \n",
    "    def get_slice_3D(x):\n",
    "        \n",
    "        if direction == 0:\n",
    "            img = container[x]\n",
    "            x_lim = container.shape[2]\n",
    "            y_lim = container.shape[1]\n",
    "            x_label = axis_labels[2]\n",
    "            y_label = axis_labels[1] \n",
    "            \n",
    "        elif direction == 1:\n",
    "            img = container[:,x,:]\n",
    "            x_lim = container.shape[2]\n",
    "            y_lim = container.shape[0] \n",
    "            x_label = axis_labels[2]\n",
    "            y_label = axis_labels[0]             \n",
    "            \n",
    "        elif direction == 2:\n",
    "            img = container[:,:,x]\n",
    "            x_lim = container.shape[1]\n",
    "            y_lim = container.shape[0]    \n",
    "            x_label = axis_labels[1]\n",
    "            y_label = axis_labels[0]             \n",
    "        \n",
    "        if size is None:\n",
    "            fig = plt.figure()\n",
    "        else:\n",
    "            fig = plt.figure(figsize=size)\n",
    "        \n",
    "        if isinstance(title, (list, tuple)):\n",
    "            dtitle = title[x]\n",
    "        else:\n",
    "            dtitle = title\n",
    "        \n",
    "        gs = gridspec.GridSpec(1, 2, figure=fig, width_ratios=(1,.05), height_ratios=(1,))\n",
    "        # image\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "      \n",
    "        ax.set_xlabel(x_label)     \n",
    "        ax.set_ylabel(y_label)\n",
    " \n",
    "        aximg = ax.imshow(img, cmap=cmap, origin='upper', extent=(0,x_lim,y_lim,0))\n",
    "        aximg.set_clim(minmax)\n",
    "        ax.set_title(dtitle + \" {}\".format(x))\n",
    "        # colorbar\n",
    "        ax = fig.add_subplot(gs[0, 1])\n",
    "        plt.colorbar(aximg, cax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.show(fig)\n",
    "        \n",
    "    return get_slice_3D\n",
    "\n",
    "    \n",
    "def islicer(data, direction, title=\"\", slice_number=None, cmap='gray', minmax=None, size=None, axis_labels=None):\n",
    "\n",
    "    '''Creates an interactive integer slider that slices a 3D volume along direction\n",
    "    \n",
    "    :param data: DataContainer or numpy array\n",
    "    :param direction: slice direction, int, should be 0,1,2 or the axis label\n",
    "    :param title: optional title for the display\n",
    "    :slice_number: int start slice number, optional. If None defaults to center slice\n",
    "    :param cmap: matplotlib color map\n",
    "    :param minmax: colorbar min and max values, defaults to min max of container\n",
    "    :param size: int or tuple specifying the figure size in inch. If int it specifies the width and scales the height keeping the standard matplotlib aspect ratio \n",
    "    '''\n",
    "    \n",
    "    if axis_labels is None:\n",
    "        if hasattr(data, \"dimension_labels\"):\n",
    "            axis_labels = [data.dimension_labels[0],data.dimension_labels[1],data.dimension_labels[2]]\n",
    "        else:\n",
    "            axis_labels = ['X', 'Y', 'Z']\n",
    "\n",
    "    \n",
    "    if hasattr(data, \"as_array\"):\n",
    "        container = data.as_array()\n",
    "        \n",
    "        if not isinstance (direction, int):\n",
    "            if direction in data.dimension_labels.values():\n",
    "                direction = data.get_dimension_axis(direction)                             \n",
    "\n",
    "    elif isinstance (data, numpy.ndarray):\n",
    "        container = data\n",
    "        \n",
    "    if slice_number is None:\n",
    "        slice_number = int(data.shape[direction]/2)\n",
    "        \n",
    "    slider = widgets.IntSlider(min=0, max=data.shape[direction]-1, step=1, \n",
    "                             value=slice_number, continuous_update=False, description=axis_labels[direction])\n",
    "\n",
    "    if minmax is None:\n",
    "        amax = container.max()\n",
    "        amin = container.min()\n",
    "    else:\n",
    "        amin = min(minmax)\n",
    "        amax = max(minmax)\n",
    "    \n",
    "    if isinstance (size, (int, float)):\n",
    "        default_ratio = 6./8.\n",
    "        size = ( size , size * default_ratio )\n",
    "    \n",
    "    interact(display_slice(container, \n",
    "                           direction, \n",
    "                           title=title, \n",
    "                           cmap=cmap, \n",
    "                           minmax=(amin, amax),\n",
    "                           size=size, axis_labels=axis_labels),\n",
    "             x=slider);\n",
    "    \n",
    "    return slider\n",
    "    \n",
    "\n",
    "def link_islicer(*args):\n",
    "    '''links islicers IntSlider widgets'''\n",
    "    linked = [(widg, 'value') for widg in args]\n",
    "    # link pair-wise\n",
    "    pairs = [(linked[i+1],linked[i]) for i in range(len(linked)-1)]\n",
    "    for pair in pairs:\n",
    "        widgets.link(*pair)\n",
    "\n",
    "def psnr(img1, img2, data_range=1):\n",
    "    mse = numpy.mean( (img1 - img2) ** 2 )\n",
    "    if mse == 0:\n",
    "        return 1000\n",
    "    return 20 * numpy.log10(data_range / numpy.sqrt(mse))\n",
    "\n",
    "\n",
    "def plotter2D(datacontainers, titles=None, fix_range=False, stretch_y=False, cmap='gray', axis_labels=None):\n",
    "    '''plotter2D(datacontainers=[], titles=[], fix_range=False, stretch_y=False, cmap='gray', axes_labels=['X','Y'])\n",
    "    \n",
    "    plots 1 or more 2D plots in an (n x 2) matix\n",
    "    multiple datasets can be passed as a list\n",
    "    \n",
    "    Can take ImageData, AquistionData or numpy.ndarray as input\n",
    "    '''\n",
    "    if(isinstance(datacontainers, list)) is False:\n",
    "        datacontainers = [datacontainers]\n",
    "\n",
    "    if titles is not None:\n",
    "        if(isinstance(titles, list)) is False:\n",
    "            titles = [titles]\n",
    "            \n",
    "\n",
    "    \n",
    "    nplots = len(datacontainers)\n",
    "    rows = int(round((nplots+0.5)/2.0))\n",
    "\n",
    "    fig, (ax) = plt.subplots(rows, 2,figsize=(15,15))\n",
    "\n",
    "    axes = ax.flatten() \n",
    "\n",
    "    range_min = float(\"inf\")\n",
    "    range_max = 0\n",
    "    \n",
    "    if fix_range == True:\n",
    "        for i in range(nplots):\n",
    "            if type(datacontainers[i]) is numpy.ndarray:\n",
    "                dc = datacontainers[i]\n",
    "            else:\n",
    "                dc = datacontainers[i].as_array()\n",
    "                \n",
    "            range_min = min(range_min, numpy.amin(dc))\n",
    "            range_max = max(range_max, numpy.amax(dc))\n",
    "        \n",
    "    for i in range(rows*2):\n",
    "        axes[i].set_visible(False)\n",
    "\n",
    "    for i in range(nplots):\n",
    "        axes[i].set_visible(True)\n",
    "        \n",
    "        if titles is not None:\n",
    "            axes[i].set_title(titles[i])\n",
    "       \n",
    "        if axis_labels is not None:\n",
    "            axes[i].set_ylabel(axis_labels[1])\n",
    "            axes[i].set_xlabel(axis_labels[0]) \n",
    "            \n",
    "        if type(datacontainers[i]) is numpy.ndarray:\n",
    "            dc = datacontainers[i]          \n",
    "        else:\n",
    "            dc = datacontainers[i].as_array()\n",
    "            \n",
    "            if axis_labels is None:\n",
    "                axes[i].set_ylabel(datacontainers[i].dimension_labels[0])\n",
    "                axes[i].set_xlabel(datacontainers[i].dimension_labels[1])        \n",
    "        \n",
    "        \n",
    "        sp = axes[i].imshow(dc, cmap=cmap, origin='upper', extent=(0,dc.shape[1],dc.shape[0],0))\n",
    "    \n",
    "        \n",
    "        im_ratio = dc.shape[0]/dc.shape[1]\n",
    "        \n",
    "        if stretch_y ==True:   \n",
    "            axes[i].set_aspect(1/im_ratio)\n",
    "            im_ratio = 1\n",
    "            \n",
    "        plt.colorbar(sp, ax=axes[i],fraction=0.0467*im_ratio, pad=0.02)\n",
    "        \n",
    "        if fix_range == True:\n",
    "            sp.set_clim(range_min,range_max) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kullback Leibler methods with numba\n",
    "try:\n",
    "    import numba\n",
    "    from numba import jit, prange\n",
    "    import numpy\n",
    "    from numpy import sqrt, log, inf\n",
    "    has_numba = True\n",
    "    '''Some parallelisation of KL calls'''\n",
    "    @jit(nopython=True)\n",
    "    def kl_proximal(x,b, bnoise, tau, out):\n",
    "            for i in prange(x.size):\n",
    "                out.flat[i] = 0.5 *  ( \n",
    "                    ( x.flat[i] - bnoise.flat[i] - tau ) +\\\n",
    "                    numpy.sqrt( (x.flat[i] + bnoise.flat[i] - tau)**2. + \\\n",
    "                        (4. * tau * b.flat[i]) \n",
    "                    )\n",
    "                )\n",
    "    @jit(nopython=True)\n",
    "    def kl_proximal_conjugate(x, b, bnoise, tau, out):\n",
    "        #z = x + tau * self.bnoise\n",
    "        #return 0.5*((z + 1) - ((z-1)**2 + 4 * tau * self.b).sqrt())\n",
    "\n",
    "        for i in prange(x.size):\n",
    "            z = x.flat[i] + ( tau * bnoise.flat[i] )\n",
    "            out.flat[i] = 0.5 * ( \n",
    "                (z + 1) - numpy.sqrt((z-1)*(z-1) + 4 * tau * b.flat[i])\n",
    "                )\n",
    "    @jit(nopython=True)\n",
    "    def kl_gradient(x, b, bnoise, out):\n",
    "        for i in prange(x.size):\n",
    "            out.flat[i] = 1 - b.flat[i]/(x.flat[i] + bnoise.flat[i])\n",
    "\n",
    "    @jit(nopython=True)\n",
    "    def kl_div(x, y, out):\n",
    "        for i in prange(x.size):\n",
    "            X = x.flat[i]\n",
    "            Y = y.flat[i]    \n",
    "            if x.flat[i] > 0 and y.flat[i] > 0:\n",
    "                out.flat[i] = X * numpy.log(X/Y) - X + Y\n",
    "            elif X == 0 and Y >= 0:\n",
    "                out.flat[i] = Y\n",
    "            else:\n",
    "                out.flat[i] = numpy.inf\n",
    "    \n",
    "    # force a jit\n",
    "    x = numpy.asarray(numpy.random.random((10,10)), dtype=numpy.float32)\n",
    "    b = numpy.asarray(numpy.random.random((10,10)), dtype=numpy.float32)\n",
    "    bnoise = numpy.zeros_like(x)\n",
    "    out = numpy.empty_like(x)\n",
    "    tau = 1.\n",
    "    kl_div(b,x,out)\n",
    "    kl_gradient(x,b,bnoise,out)\n",
    "    kl_proximal(x,b, bnoise, tau, out)\n",
    "    kl_proximal_conjugate(x,b, bnoise, tau, out)\n",
    "\n",
    "except ImportError as ie:\n",
    "    has_numba = False\n",
    "\n",
    "class ChangeSign(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_instance(class_name, *args,**kwargs):\n",
    "        \n",
    "        setattr(class_name, '__call__', ChangeSign.KL_call)\n",
    "        setattr(class_name, 'gradient', ChangeSign.KL_gradient)\n",
    "        setattr(class_name, 'proximal_conjugate', ChangeSign.KL_proximal_conjugate)\n",
    "        \n",
    "        instance = class_name(*args, **kwargs)\n",
    "        # swap the original set_acquisition_data with a modified one\n",
    "        set_acquisition_data_sirf = instance.set_acquisition_data\n",
    "        setattr(class_name, 'set_acquisition_data_sirf', set_acquisition_data_sirf)\n",
    "        setattr(class_name, 'set_acquisition_data', ChangeSign.set_acquisition_data)\n",
    "        \n",
    "        # return the new instance\n",
    "        return instance\n",
    "\n",
    "    ### Few fixes for common interface\n",
    "    @staticmethod\n",
    "    def set_acquisition_data(self, ad):\n",
    "        #save a reference to acquisition_data in the class\n",
    "        self.b = ad\n",
    "        self.set_acquisition_data_sirf(ad)\n",
    "        \n",
    "    @staticmethod\n",
    "    def KL_call(self, x):\n",
    "        return - self.get_value(x)\n",
    "    @staticmethod\n",
    "    def KL_gradient(self, image, subset = -1, out = None):\n",
    "\n",
    "        assert_validity(image, pet.ImageData)\n",
    "        grad = pet.ImageData()\n",
    "        grad.handle = pystir.cSTIR_objectiveFunctionGradient\\\n",
    "            (self.handle, image.handle, subset)\n",
    "        check_status(grad.handle)\n",
    "        # change sign\n",
    "        #grad*=-1\n",
    "        if out is None:\n",
    "            return -1 * grad  \n",
    "        else:\n",
    "            out.fill(-1 * grad)\n",
    "    @staticmethod\n",
    "    def KL_proximal_conjugate(self, x, tau, out=None):\n",
    "\n",
    "        r'''Proximal operator of the convex conjugate of KullbackLeibler at x:\n",
    "\n",
    "           .. math::     prox_{\\tau * f^{*}}(x)\n",
    "        '''\n",
    "        \n",
    "        self.bnoise = x * 0.\n",
    "        if has_numba:\n",
    "            if out is None:\n",
    "                out = (x * 0.)\n",
    "                out_np = out.as_array()\n",
    "                kl_proximal_conjugate(x.as_array(), self.b.as_array(), self.bnoise.as_array(), tau, out_np)\n",
    "                out.fill(out_np)\n",
    "                return out\n",
    "            else:\n",
    "                out_np = out.as_array()\n",
    "                kl_proximal_conjugate(x.as_array(), self.b.as_array(), self.bnoise.as_array(), tau, out_np)\n",
    "                out.fill(out_np)                    \n",
    "        else:\n",
    "            if out is None:\n",
    "                z = x + tau * self.bnoise\n",
    "                return 0.5*((z + 1) - ((z-1)**2 + 4 * tau * self.b).sqrt())\n",
    "            else:\n",
    "                \n",
    "                tmp = tau * self.bnoise\n",
    "                tmp += x\n",
    "                tmp -= 1\n",
    "                \n",
    "                self.b.multiply(4*tau, out=out)    \n",
    "                \n",
    "                out.add(tmp.power(2), out=out)\n",
    "                out.sqrt(out=out)\n",
    "                out *= -1\n",
    "                tmp += 2\n",
    "                out += tmp\n",
    "                out *= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of emission: (127, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Define norm for the acquisition model\n",
    "def norm(self, **kwargs):\n",
    "    return LinearOperator.PowerMethod(self, kwargs.get('iterations',10))[0]\n",
    "\n",
    "setattr(pet.AcquisitionModelUsingRayTracingMatrix, 'norm', norm)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#% go to directory with input files\n",
    "\n",
    "EXAMPLE = 'SIMULATION'\n",
    "\n",
    "\n",
    "if EXAMPLE == 'SIMULATION':\n",
    "    data_dir = os.path.abspath('/home/edo/GitHub/PETMR/SRS_data_exhale')\n",
    "    os.chdir(data_dir)\n",
    "    ##%% copy files to working folder and change directory to where the output files are\n",
    "    new_dir = os.path.abspath(os.path.join(data_dir, 'exhale-output-CIL-numba'))\n",
    "    \n",
    "    # adapt this path to your situation (or start everything in the relevant directory)\n",
    "    #os.chdir('/mnt/data/CCPPETMR/201909_hackathon/Simulations/PET/SimulationData')\n",
    "    #shutil.rmtree(new_dir,True)\n",
    "    if not os.path.exists(new_dir):\n",
    "        shutil.copytree(data_dir,new_dir)\n",
    "    os.chdir(new_dir)\n",
    "    \n",
    "    attenuation_header = 'PET_attenuation.nii'\n",
    "    image_header = attenuation_header\n",
    "    sinogram_header = 'noisy_sino.hs'\n",
    "\n",
    "elif EXAMPLE == 'SMALL':\n",
    "    # adapt this path to your situation (or start everything in the relevant directory)\n",
    "    os.chdir(examples_data_path('PET'))\n",
    "    #\n",
    "    ##%% copy files to working folder and change directory to where the output files are\n",
    "    shutil.rmtree('working_folder/thorax_single_slice',True)\n",
    "    shutil.copytree('thorax_single_slice','working_folder/thorax_single_slice')\n",
    "    os.chdir('working_folder/thorax_single_slice')\n",
    "    \n",
    "    image_header = 'emission.hv'\n",
    "    attenuation_header = 'attenuation.hv'\n",
    "    sinogram_header = 'template_sinogram.hs'\n",
    "\n",
    "    \n",
    "elif EXAMPLE == 'BRAIN':\n",
    "    # adapt this path to your situation (or start everything in the relevant directory)\n",
    "    os.chdir(examples_data_path('PET'))\n",
    "    #\n",
    "    ##%% copy files to working folder and change directory to where the output files are\n",
    "    shutil.rmtree('working_folder/brain',True)\n",
    "    shutil.copytree('brain','working_folder/brain')\n",
    "    os.chdir('working_folder/brain')\n",
    "    \n",
    "    image_header = 'emission.hv'\n",
    "    attenuation_header = 'attenuation.hv'\n",
    "    sinogram_header = 'template_sinogram.hs'\n",
    "\n",
    "# Read in images\n",
    "    \n",
    "image = pet.ImageData(image_header);\n",
    "image_array=image.as_array()\n",
    "mu_map = pet.ImageData(attenuation_header);\n",
    "mu_map_array=mu_map.as_array();\n",
    "\n",
    "# Show Emission image\n",
    "print('Size of emission: {}'.format(image.shape))\n",
    "\n",
    "# plt.imshow(image.as_array()[0])\n",
    "# plt.colorbar()\n",
    "# plt.title('Emission')\n",
    "# #plt.show()\n",
    "\n",
    "# plt.imshow(mu_map.as_array()[0])\n",
    "# plt.colorbar()\n",
    "# plt.title('Attenuation')\n",
    "#plt.show()\n",
    "\n",
    "#%%\n",
    "\n",
    "am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "# we will increate the number of rays used for every Line-of-Response (LOR) as an example\n",
    "# (it is not required for the exercise of course)\n",
    "am.set_num_tangential_LORs(5)\n",
    "templ = pet.AcquisitionData(sinogram_header)\n",
    "# rebin the data to speed up\n",
    "templ = templ.rebin(11)\n",
    "# this seems to use a lot of memory! 256 Gb went!\n",
    "# pet.AcquisitionData.set_storage_scheme('memory')\n",
    "am.set_up(templ,image)\n",
    "\n",
    "#% simulate some data using forward projection\n",
    "if EXAMPLE == 'SIMULATION':\n",
    "    \n",
    "    acquired_data = templ\n",
    "    image.fill(1)\n",
    "    noisy_data = acquired_data.clone()\n",
    "\n",
    "elif EXAMPLE in ['SMALL', 'BRAIN']:\n",
    "    \n",
    "    acquired_data=am.forward(image)\n",
    "    \n",
    "    acquisition_array = acquired_data.as_array()\n",
    "\n",
    "    np.random.seed(10)\n",
    "    noisy_data = acquired_data.clone()\n",
    "    scale = 100\n",
    "    noisy_array = scale * np.random.poisson(acquisition_array/scale).astype('float64')\n",
    "    print(' Maximum counts in the data: %d' % noisy_array.max())\n",
    "    noisy_data.fill(noisy_array)\n",
    "\n",
    "\n",
    "\n",
    "#%% Display bitmaps of a middle sinogram\n",
    "    \n",
    "#     plt.imshow(noisy_array[0,0,:,:])\n",
    "#     plt.title('Acquisition Data')\n",
    "#     plt.show()\n",
    "\n",
    "# Show util per iteration\n",
    "def show_data(it, obj, x):\n",
    "    plt.imshow(x.as_array()[0])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating operator norm\n",
      "done\n",
      "PDHG setting up\n",
      "PDHG configured\n",
      "     Iter   Max Iter     Time/Iter            Objective\n",
      "                               [s]                     \n",
      "        0        500         0.000          5.24604e+06\n",
      "        2        500        11.177          2.05889e+06\n"
     ]
    }
   ],
   "source": [
    "#%% TV reconstruction using algorithm below\n",
    "\n",
    "alpha = 0\n",
    "\n",
    "ALGORITHM = 'PDHG_SIRF' # or PDHG_CIL, PDHG_SIRF, FISTA_CIL, FISTA_SIRF, OSMAPOSL\n",
    "\n",
    "if  ALGORITHM == 'PDHG_SIRF':\n",
    "    \n",
    "    method = 'implicit'\n",
    "    \n",
    "    if method == 'explicit':\n",
    "        \n",
    "        # Create operators\n",
    "        op1 = GradientSIRF(image) \n",
    "        op2 = am\n",
    "    \n",
    "        # Create BlockOperator\n",
    "        operator = BlockOperator(op1, op2, shape=(2,1) ) \n",
    "        \n",
    "        f2 = KullbackLeibler(noisy_data)  \n",
    "        g =  IndicatorBox(lower=0)    \n",
    "                \n",
    "        f1 = alpha * MixedL21Norm() \n",
    "        f = BlockFunction(f1, f2)  \n",
    "        normK = operator.norm()\n",
    "        \n",
    "    elif method == 'implicit':\n",
    "        \n",
    "        operator = am      \n",
    "        # refdata, regularisation_parameter, iterations, tolerance, eta_const, methodTV, nonneg, device\n",
    "        #g = FGP_dTV(mu_map, alpha, 500, 1e-7, 1e-2, 0, 1, 'gpu' )\n",
    "        #g = FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' ) \n",
    "        # f = KullbackLeibler(noisy_data)\n",
    "        if alpha == 0:\n",
    "            g = IndicatorBox(lower=0)\n",
    "        else:\n",
    "            g = FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' )\n",
    "            \n",
    "#         fidelity = pet.PoissonLogLikelihoodWithLinearModelForMeanAndProjData()\n",
    "\n",
    "        fidelity = ChangeSign.get_instance(pet.PoissonLogLikelihoodWithLinearModelForMeanAndProjData)  \n",
    "        fidelity.set_acquisition_model(am)\n",
    "        fidelity.set_acquisition_data(noisy_data)\n",
    "        fidelity.set_num_subsets(4)\n",
    "        fidelity.set_up(image)\n",
    "        fidelity.L = 1e4\n",
    "        print (\"Calculating operator norm\")\n",
    "        normK = operator.norm(iterations=5)\n",
    "        print (\"done\")\n",
    "         \n",
    "    sigma = 100.\n",
    "    tau = 1/(sigma*normK**2)      \n",
    "        \n",
    "    # Setup and run the PDHG algorithm\n",
    "    def sirf_update_objective(self):\n",
    "\n",
    "        p1 = self.f((self.x)) + self.g(self.x)\n",
    "        #d1 = -(self.f.convex_conjugate(self.y) + self.g.convex_conjugate(-1*self.operator.adjoint(self.y)))\n",
    "        #p1 = 0.\n",
    "        #d1 = 0.\n",
    "        #self.loss.append([p1, d1, p1-d1])\n",
    "        self.loss.append(p1)\n",
    "        \n",
    "    setattr(PDHG, 'update_objective', sirf_update_objective )\n",
    "    algo = PDHG(f = fidelity, g = g, operator = operator, tau = tau, sigma = sigma)\n",
    "    algo.max_iteration = 500\n",
    "    algo.update_objective_interval = 2\n",
    "    algo.run(2)\n",
    "        \n",
    "        \n",
    "    \n",
    "elif ALGORITHM == 'OSMAPOSL':\n",
    "    \n",
    "    fidelity = pet.PoissonLogLikelihoodWithLinearModelForMeanAndProjData()\n",
    "    fidelity.set_acquisition_model(am)\n",
    "    fidelity.set_acquisition_data(noisy_data)\n",
    "    fidelity.set_num_subsets(4)\n",
    "    fidelity.set_up(image)\n",
    "    \n",
    "    recon = pet.OSMAPOSLReconstructor()\n",
    "    recon.set_objective_function(fidelity)\n",
    "    recon.set_num_subsets(4)\n",
    "    num_iters=10;\n",
    "    recon.set_num_subiterations(num_iters)\n",
    "    \n",
    "    reconstructed_image = image.allocate(1)\n",
    "    recon.set_up(reconstructed_image)\n",
    "    recon.reconstruct(reconstructed_image)\n",
    "\n",
    "    plt.imshow(recon.get_output().as_array()[0])\n",
    "    plt.colorbar()\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# load MR data for dTV\n",
    "refdata = pet.ImageData('MR_T2.nii')\n",
    "print (refdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### how to find a proper alpha\n",
    "alpha = 5.\n",
    "obj = []\n",
    "r_iterations = 500\n",
    "r_alpha = alpha\n",
    "r_tolerance = 1e-7\n",
    "r_eta_const = 1e-2\n",
    "r_iso = 0\n",
    "r_nonneg = 1\n",
    "#FGP_dTV(refdata, r_alpha, r_iterations, r_tolerance, r_eta_const, r_iso, r_nonneg, device='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDHG setting up\n",
      "PDHG configured\n",
      "     Iter   Max Iter     Time/Iter            Objective\n",
      "                               [s]                     \n",
      "        0        500         0.000          5.24604e+06\n",
      "       10        500         9.570          2.05889e+06\n",
      "       20        500         9.049          1.54879e+06\n",
      "       30        500         9.266          1.52572e+06\n",
      "       40        500         9.220          1.51780e+06\n",
      "       50        500         9.133          1.51334e+06\n"
     ]
    }
   ],
   "source": [
    "# reset algo and run 500 iterations\n",
    "# it should take 86.107 s/iter * 500 iter / 3600 s/h = 11.9 h\n",
    "alphas = [ 50., 50., 0.,]\n",
    "gs = [ FGP_dTV(refdata, r_alpha, r_iterations, r_tolerance, r_eta_const, r_iso, r_nonneg, device='gpu'), \n",
    "      FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' ), IndicatorBox(lower=0.)]\n",
    "regul = ['FGP_dTV', 'FGP_TV', 'IndicatorBox']\n",
    "for alpha, g, reg in zip([alphas[-1]], [gs[-1]], [regul[-1]]):\n",
    "    algo = PDHG(f = fidelity, g = g, operator = operator, tau = tau, sigma = sigma)\n",
    "    algo.max_iteration = 500\n",
    "    algo.update_objective_interval = 10\n",
    "\n",
    "    if False:\n",
    "        run = 10\n",
    "        for i in range(algo.max_iteration / run):\n",
    "            algo.run(run)\n",
    "            # saves to os.getcwd()\n",
    "            #print (os.getcwd())\n",
    "            fname = os.path.join(os.getcwd(),\"PDHG_{}_alpha{}_iter_{}\".format(reg,alpha,algo.iteration))\n",
    "            algo.get_output().write(fname)\n",
    "    else:\n",
    "        def save_output(iteration,obj,x):\n",
    "            alpha = 0\n",
    "            fname = os.path.join(os.getcwd(),\"PDHG_{}_alpha{}_iter_{}\".format(reg,alpha,iteration))\n",
    "            x.write(fname)\n",
    "\n",
    "        algo.run(500,callback=save_output,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(os.getcwd(),\"PDHG_FGP_alpha{}_iter_{}\".format(alpha,algo.iteration))\n",
    "print (os.getcwd(), alpha, fname)\n",
    "algo.get_output().write(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccpi.io import NEXUSReader\n",
    "fname = os.path.join(os.getcwd(),\"PDHG_FGP_alpha{}_iter_{}\".format(alpha,100))\n",
    "read = NEXUSReader()\n",
    "read.set_up(nexus_file=fname)\n",
    "read.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s1 = islicer(algo.get_output().as_array(), 0, \"PDHG iter {}\".format(algo.iteration))\n",
    "s0 = islicer(solution_4.as_array(), 0, \"PDHG iter {}\".format(4))\n",
    "\n",
    "link_islicer(s1,s0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves to os.getcwd()\n",
    "#print (os.getcwd())\n",
    "\n",
    "\n",
    "algo.get_output().write(\"PDHG_FGP_alpha{}_iter_{}\".format(alpha,algo.iteration))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
