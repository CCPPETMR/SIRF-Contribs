{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Initial imports etc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import pSTIR as pet\n",
    "\n",
    "from sirf.Utilities import examples_data_path\n",
    "from ccpi.optimisation.algorithms import CGLS, PDHG, FISTA\n",
    "from ccpi.optimisation.operators import BlockOperator, LinearOperator\n",
    "from ccpi.optimisation.functions import KullbackLeibler, IndicatorBox, \\\n",
    "         FunctionOperatorComposition, BlockFunction, MixedL21Norm , ZeroFunction, KullbackLeibler\n",
    "from ccpi.framework import ImageData\n",
    "from ccpi.plugins.regularisers import FGP_TV#, FGP_dTV\n",
    "setattr(FGP_TV, 'convex_conjugate', lambda self,x: 0.0)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "    import numba\n",
    "    from numba import jit, prange\n",
    "    import numpy\n",
    "    from numpy import sqrt, log, inf\n",
    "    has_numba = True\n",
    "    '''Some parallelisation of KL calls'''\n",
    "    @jit(nopython=True)\n",
    "    def kl_proximal(x,b, bnoise, tau, out):\n",
    "            for i in prange(x.size):\n",
    "                out.flat[i] = 0.5 *  ( \n",
    "                    ( x.flat[i] - bnoise.flat[i] - tau ) +\\\n",
    "                    numpy.sqrt( (x.flat[i] + bnoise.flat[i] - tau)**2. + \\\n",
    "                        (4. * tau * b.flat[i]) \n",
    "                    )\n",
    "                )\n",
    "    @jit(nopython=True)\n",
    "    def kl_proximal_conjugate(x, b, bnoise, tau, out):\n",
    "        #z = x + tau * self.bnoise\n",
    "        #return 0.5*((z + 1) - ((z-1)**2 + 4 * tau * self.b).sqrt())\n",
    "\n",
    "        for i in prange(x.size):\n",
    "            z = x.flat[i] + ( tau * bnoise.flat[i] )\n",
    "            out.flat[i] = 0.5 * ( \n",
    "                (z + 1) - numpy.sqrt((z-1)*(z-1) + 4 * tau * b.flat[i])\n",
    "                )\n",
    "    @jit(nopython=True)\n",
    "    def kl_gradient(x, b, bnoise, out):\n",
    "        for i in prange(x.size):\n",
    "            out.flat[i] = 1 - b.flat[i]/(x.flat[i] + bnoise.flat[i])\n",
    "\n",
    "    @jit(nopython=True)\n",
    "    def kl_div(x, y, out):\n",
    "        for i in prange(x.size):\n",
    "            X = x.flat[i]\n",
    "            Y = y.flat[i]    \n",
    "            if x.flat[i] > 0 and y.flat[i] > 0:\n",
    "                out.flat[i] = X * numpy.log(X/Y) - X + Y\n",
    "            elif X == 0 and Y >= 0:\n",
    "                out.flat[i] = Y\n",
    "            else:\n",
    "                out.flat[i] = numpy.inf\n",
    "    \n",
    "    # force a jit\n",
    "    x = numpy.asarray(numpy.random.random((10,10)), dtype=numpy.float32)\n",
    "    b = numpy.asarray(numpy.random.random((10,10)), dtype=numpy.float32)\n",
    "    bnoise = numpy.zeros_like(x)\n",
    "    out = numpy.empty_like(x)\n",
    "    tau = 1.\n",
    "    kl_div(b,x,out)\n",
    "    kl_gradient(x,b,bnoise,out)\n",
    "    kl_proximal(x,b, bnoise, tau, out)\n",
    "    kl_proximal_conjugate(x,b, bnoise, tau, out)\n",
    "\n",
    "except ImportError as ie:\n",
    "    has_numba = False\n",
    "\n",
    "class ChangeSign(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_instance(class_name, *args,**kwargs):\n",
    "        \n",
    "        setattr(class_name, '__call__', ChangeSign.KL_call)\n",
    "        setattr(class_name, 'gradient', ChangeSign.KL_gradient)\n",
    "        setattr(class_name, 'proximal_conjugate', ChangeSign.KL_proximal_conjugate)\n",
    "        \n",
    "        instance = class_name(*args, **kwargs)\n",
    "        # swap the original set_acquisition_data with a modified one\n",
    "        set_acquisition_data_sirf = instance.set_acquisition_data\n",
    "        setattr(class_name, 'set_acquisition_data_sirf', set_acquisition_data_sirf)\n",
    "        setattr(class_name, 'set_acquisition_data', ChangeSign.set_acquisition_data)\n",
    "        \n",
    "        # return the new instance\n",
    "        return instance\n",
    "\n",
    "    ### Few fixes for common interface\n",
    "    @staticmethod\n",
    "    def set_acquisition_data(self, ad):\n",
    "        #save a reference to acquisition_data in the class\n",
    "        self.b = ad\n",
    "        self.set_acquisition_data_sirf(ad)\n",
    "        \n",
    "    @staticmethod\n",
    "    def KL_call(self, x):\n",
    "        return - self.get_value(x)\n",
    "    @staticmethod\n",
    "    def KL_gradient(self, image, subset = -1, out = None):\n",
    "\n",
    "        assert_validity(image, pet.ImageData)\n",
    "        grad = pet.ImageData()\n",
    "        grad.handle = pystir.cSTIR_objectiveFunctionGradient\\\n",
    "            (self.handle, image.handle, subset)\n",
    "        check_status(grad.handle)\n",
    "        # change sign\n",
    "        #grad*=-1\n",
    "        if out is None:\n",
    "            return -1 * grad  \n",
    "        else:\n",
    "            out.fill(-1 * grad)\n",
    "    @staticmethod\n",
    "    def KL_proximal_conjugate(self, x, tau, out=None):\n",
    "\n",
    "        r'''Proximal operator of the convex conjugate of KullbackLeibler at x:\n",
    "\n",
    "           .. math::     prox_{\\tau * f^{*}}(x)\n",
    "        '''\n",
    "        \n",
    "        self.bnoise = x * 0.\n",
    "        if has_numba:\n",
    "            if out is None:\n",
    "                out = (x * 0.)\n",
    "                out_np = out.as_array()\n",
    "                kl_proximal_conjugate(x.as_array(), self.b.as_array(), self.bnoise.as_array(), tau, out_np)\n",
    "                out.fill(out_np)\n",
    "                return out\n",
    "            else:\n",
    "                out_np = out.as_array()\n",
    "                kl_proximal_conjugate(x.as_array(), self.b.as_array(), self.bnoise.as_array(), tau, out_np)\n",
    "                out.fill(out_np)                    \n",
    "        else:\n",
    "            if out is None:\n",
    "                z = x + tau * self.bnoise\n",
    "                return 0.5*((z + 1) - ((z-1)**2 + 4 * tau * self.b).sqrt())\n",
    "            else:\n",
    "                \n",
    "                tmp = tau * self.bnoise\n",
    "                tmp += x\n",
    "                tmp -= 1\n",
    "                \n",
    "                self.b.multiply(4*tau, out=out)    \n",
    "                \n",
    "                out.add(tmp.power(2), out=out)\n",
    "                out.sqrt(out=out)\n",
    "                out *= -1\n",
    "                tmp += 2\n",
    "                out += tmp\n",
    "                out *= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of emission: (127, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Define norm for the acquisition model\n",
    "def norm(self, **kwargs):\n",
    "    return LinearOperator.PowerMethod(self, kwargs.get('iterations',10))[0]\n",
    "\n",
    "setattr(pet.AcquisitionModelUsingRayTracingMatrix, 'norm', norm)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#% go to directory with input files\n",
    "\n",
    "EXAMPLE = 'SIMULATION'\n",
    "\n",
    "\n",
    "if EXAMPLE == 'SIMULATION':\n",
    "    \n",
    "    # adapt this path to your situation (or start everything in the relevant directory)\n",
    "    os.chdir('/mnt/data/CCPPETMR/201909_hackathon/Simulations/PET/SimulationData')\n",
    "    ##%% copy files to working folder and change directory to where the output files are\n",
    "    new_dir = 'exhale-output-CIL-numba'\n",
    "    \n",
    "    #shutil.rmtree(new_dir,True)\n",
    "    #shutil.copytree('Exhale',new_dir)\n",
    "    os.chdir(new_dir)\n",
    "    \n",
    "    attenuation_header = 'pet_dyn_4D_resp_simul_dynamic_0_state_0_attenuation_map.hv'\n",
    "    image_header = attenuation_header\n",
    "    sinogram_header = 'pet_dyn_4D_resp_simul_dynamic_0_state_0.hs'\n",
    "\n",
    "elif EXAMPLE == 'SMALL':\n",
    "    # adapt this path to your situation (or start everything in the relevant directory)\n",
    "    os.chdir(examples_data_path('PET'))\n",
    "    #\n",
    "    ##%% copy files to working folder and change directory to where the output files are\n",
    "    shutil.rmtree('working_folder/thorax_single_slice',True)\n",
    "    shutil.copytree('thorax_single_slice','working_folder/thorax_single_slice')\n",
    "    os.chdir('working_folder/thorax_single_slice')\n",
    "    \n",
    "    image_header = 'emission.hv'\n",
    "    attenuation_header = 'attenuation.hv'\n",
    "    sinogram_header = 'template_sinogram.hs'\n",
    "\n",
    "    \n",
    "elif EXAMPLE == 'BRAIN':\n",
    "    # adapt this path to your situation (or start everything in the relevant directory)\n",
    "    os.chdir(examples_data_path('PET'))\n",
    "    #\n",
    "    ##%% copy files to working folder and change directory to where the output files are\n",
    "    shutil.rmtree('working_folder/brain',True)\n",
    "    shutil.copytree('brain','working_folder/brain')\n",
    "    os.chdir('working_folder/brain')\n",
    "    \n",
    "    image_header = 'emission.hv'\n",
    "    attenuation_header = 'attenuation.hv'\n",
    "    sinogram_header = 'template_sinogram.hs'\n",
    "\n",
    "# Read in images\n",
    "    \n",
    "image = pet.ImageData(image_header);\n",
    "image_array=image.as_array()\n",
    "mu_map = pet.ImageData(attenuation_header);\n",
    "mu_map_array=mu_map.as_array();\n",
    "\n",
    "# Show Emission image\n",
    "print('Size of emission: {}'.format(image.shape))\n",
    "\n",
    "# plt.imshow(image.as_array()[0])\n",
    "# plt.colorbar()\n",
    "# plt.title('Emission')\n",
    "# #plt.show()\n",
    "\n",
    "# plt.imshow(mu_map.as_array()[0])\n",
    "# plt.colorbar()\n",
    "# plt.title('Attenuation')\n",
    "#plt.show()\n",
    "\n",
    "#%%\n",
    "\n",
    "am = pet.AcquisitionModelUsingRayTracingMatrix()\n",
    "# we will increate the number of rays used for every Line-of-Response (LOR) as an example\n",
    "# (it is not required for the exercise of course)\n",
    "am.set_num_tangential_LORs(5)\n",
    "templ = pet.AcquisitionData(sinogram_header)\n",
    "# this seems to use a lot of memory! 256 Gb went!\n",
    "# pet.AcquisitionData.set_storage_scheme('memory')\n",
    "am.set_up(templ,image)\n",
    "\n",
    "#% simulate some data using forward projection\n",
    "if EXAMPLE == 'SIMULATION':\n",
    "    \n",
    "    acquired_data = templ\n",
    "    image.fill(1)\n",
    "    noisy_data = acquired_data.clone()\n",
    "\n",
    "elif EXAMPLE in ['SMALL', 'BRAIN']:\n",
    "    \n",
    "    acquired_data=am.forward(image)\n",
    "    \n",
    "    acquisition_array = acquired_data.as_array()\n",
    "\n",
    "    np.random.seed(10)\n",
    "    noisy_data = acquired_data.clone()\n",
    "    scale = 100\n",
    "    noisy_array = scale * np.random.poisson(acquisition_array/scale).astype('float64')\n",
    "    print(' Maximum counts in the data: %d' % noisy_array.max())\n",
    "    noisy_data.fill(noisy_array)\n",
    "\n",
    "\n",
    "\n",
    "#%% Display bitmaps of a middle sinogram\n",
    "    \n",
    "#     plt.imshow(noisy_array[0,0,:,:])\n",
    "#     plt.title('Acquisition Data')\n",
    "#     plt.show()\n",
    "\n",
    "# Show util per iteration\n",
    "def show_data(it, obj, x):\n",
    "    plt.imshow(x.as_array()[0])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating operator norm\n",
      "done\n",
      "PDHG setting up\n",
      "PDHG configured\n",
      "     Iter   Max Iter     Time/Iter            Objective\n",
      "                               [s]                     \n",
      "        0        500         0.000          5.73073e+07\n",
      "        2        500        39.498          2.65576e+07\n"
     ]
    }
   ],
   "source": [
    "#%% TV reconstruction using algorithm below\n",
    "\n",
    "alpha = 0\n",
    "\n",
    "ALGORITHM = 'PDHG_SIRF' # or PDHG_CIL, PDHG_SIRF, FISTA_CIL, FISTA_SIRF, OSMAPOSL\n",
    "\n",
    "if  ALGORITHM == 'PDHG_SIRF':\n",
    "    \n",
    "    method = 'implicit'\n",
    "    \n",
    "    if method == 'explicit':\n",
    "        \n",
    "        # Create operators\n",
    "        op1 = GradientSIRF(image) \n",
    "        op2 = am\n",
    "    \n",
    "        # Create BlockOperator\n",
    "        operator = BlockOperator(op1, op2, shape=(2,1) ) \n",
    "        \n",
    "        f2 = KullbackLeibler(noisy_data)  \n",
    "        g =  IndicatorBox(lower=0)    \n",
    "                \n",
    "        f1 = alpha * MixedL21Norm() \n",
    "        f = BlockFunction(f1, f2)  \n",
    "        normK = operator.norm()\n",
    "        \n",
    "    elif method == 'implicit':\n",
    "        \n",
    "        operator = am      \n",
    "        # refdata, regularisation_parameter, iterations, tolerance, eta_const, methodTV, nonneg, device\n",
    "        #g = FGP_dTV(mu_map, alpha, 500, 1e-7, 1e-2, 0, 1, 'gpu' )\n",
    "        #g = FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' ) \n",
    "        # f = KullbackLeibler(noisy_data)\n",
    "        if alpha == 0:\n",
    "            g = IndicatorBox(lower=0)\n",
    "        else:\n",
    "            g = FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' )\n",
    "            \n",
    "#         fidelity = pet.PoissonLogLikelihoodWithLinearModelForMeanAndProjData()\n",
    "\n",
    "        fidelity = ChangeSign.get_instance(pet.PoissonLogLikelihoodWithLinearModelForMeanAndProjData)  \n",
    "        fidelity.set_acquisition_model(am)\n",
    "        fidelity.set_acquisition_data(noisy_data)\n",
    "        fidelity.set_num_subsets(4)\n",
    "        fidelity.set_up(image)\n",
    "        fidelity.L = 1e4\n",
    "        print (\"Calculating operator norm\")\n",
    "        normK = operator.norm(iterations=5)\n",
    "        print (\"done\")\n",
    "         \n",
    "    sigma = 100.\n",
    "    tau = 1/(sigma*normK**2)      \n",
    "        \n",
    "    # Setup and run the PDHG algorithm\n",
    "    def sirf_update_objective(self):\n",
    "\n",
    "        p1 = self.f((self.x)) + self.g(self.x)\n",
    "        #d1 = -(self.f.convex_conjugate(self.y) + self.g.convex_conjugate(-1*self.operator.adjoint(self.y)))\n",
    "        #p1 = 0.\n",
    "        #d1 = 0.\n",
    "        #self.loss.append([p1, d1, p1-d1])\n",
    "        self.loss.append(p1)\n",
    "        \n",
    "    setattr(PDHG, 'update_objective', sirf_update_objective )\n",
    "    algo = PDHG(f = fidelity, g = g, operator = operator, tau = tau, sigma = sigma)\n",
    "    algo.max_iteration = 500\n",
    "    algo.update_objective_interval = 2\n",
    "    algo.run(2)\n",
    "        \n",
    "        \n",
    "    \n",
    "elif ALGORITHM == 'OSMAPOSL':\n",
    "    \n",
    "    fidelity = pet.PoissonLogLikelihoodWithLinearModelForMeanAndProjData()\n",
    "    fidelity.set_acquisition_model(am)\n",
    "    fidelity.set_acquisition_data(noisy_data)\n",
    "    fidelity.set_num_subsets(4)\n",
    "    fidelity.set_up(image)\n",
    "    \n",
    "    recon = pet.OSMAPOSLReconstructor()\n",
    "    recon.set_objective_function(fidelity)\n",
    "    recon.set_num_subsets(4)\n",
    "    num_iters=10;\n",
    "    recon.set_num_subiterations(num_iters)\n",
    "    \n",
    "    reconstructed_image = image.allocate(1)\n",
    "    recon.set_up(reconstructed_image)\n",
    "    recon.reconstruct(reconstructed_image)\n",
    "\n",
    "    plt.imshow(recon.get_output().as_array()[0])\n",
    "    plt.colorbar()\n",
    "    plt.show()    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### how to find a proper alpha\n",
    "alpha = 50.\n",
    "obj = []\n",
    "for g in [FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' ) , IndicatorBox(lower=0.)]:\n",
    "    algo = PDHG(f = fidelity, g = g, operator = operator, tau = tau, sigma = sigma)\n",
    "    algo.max_iteration = 500\n",
    "    algo.update_objective_interval = 2\n",
    "    algo.run(10)\n",
    "    obj.append(algo.objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphadata = obj[:]\n",
    "# plt.semilogy(obj[0][2:], 'r-', label='no regularisation')\n",
    "# plt.semilogy(obj[1][2:], 'g-', label='alpha=1.')\n",
    "# plt.show()\n",
    "\n",
    "print (alphadata[0])\n",
    "DF0 = ( alphadata[0][-1] - alphadata[0][2] )\n",
    "DF1  = ( alphadata[1][-1] - alphadata[1][2])\n",
    "#DF50  = ( alphadata[2][-1] - alphadata[2][2])\n",
    "beta = (DF1 / DF0 )-1\n",
    "print (\"beta = {} \\nalpha = {}\".format(beta, abs(1/beta)))\n",
    "#beta = (DF50 / DF0 )-1\n",
    "#print (\"beta = {} \\nalpha = {}\".format(beta, abs(1/beta)))\n",
    "\n",
    "\n",
    "print (alphadata[0] , alphadata[1])\n",
    "# delta is the difference between the objective function with regularisation (alpha=1.) and no regularisation\n",
    "delta =  numpy.asarray(alphadata[1]) - numpy.asarray(alphadata[0])\n",
    "x = [i for i in range(len(delta[2:]))]\n",
    "onedfit = numpy.polyfit([i for i in range(len(delta[2:]))], delta[2:],1)\n",
    "fit_fn = numpy.poly1d(onedfit)\n",
    "print (fit_fn)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(delta[2:], 'go', label='alpha=1.')\n",
    "plt.plot(x, fit_fn(x))\n",
    "plt.show()\n",
    "\n",
    "d_noreg = alphadata[0][-1] - alphadata[0][0]\n",
    "d_reg = delta[-1] - delta[0]\n",
    "\n",
    "beta = d_noreg / d_reg\n",
    "print (\"gradient ratio  = {}\".format(delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_fn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c28d85356642fc8ad0eb798bf28370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KEludFNsaWRlcih2YWx1ZT0wLCBjb250aW51b3VzX3VwZGF0ZT1GYWxzZSwgZGVzY3JpcHRpb249dSd4JywgbWF4PTEyNyksIE91dHB1dCgpKSwgX2RvbV/igKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffee8d0bc4f4a51afe46ec1a30f4945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, continuous_update=False, description=u'x', max=127)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sliceno = 10\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(algo.get_output().as_array()[sliceno])\n",
    "# plt.title('{} iter {}'.format(algo.__class__.__name__, algo.iteration))\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.plot(algo.get_output().as_array()[sliceno][50])\n",
    "# plt.show()\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import numpy\n",
    "\n",
    "def display_slice(container, direction, title, cmap, minmax):\n",
    "    \n",
    "        \n",
    "    def get_slice_3D(x):\n",
    "        \n",
    "        if direction == 0:\n",
    "            img = container[x]\n",
    "        elif direction == 1:\n",
    "            img = container[:,x,:]\n",
    "        elif direction == 2:\n",
    "            img = container[:,:,x]\n",
    "        \n",
    "        fig = plt.figure()\n",
    "        gs = gridspec.GridSpec(1, 2, figure=fig, width_ratios=(1,.05))\n",
    "        # image\n",
    "        ax = fig.add_subplot(gs[0, 0])\n",
    "        aximg = ax.imshow(img, cmap=cmap)\n",
    "        aximg.set_clim(minmax)\n",
    "        ax.set_title(title + \" {}\".format(x))\n",
    "        # colorbar\n",
    "        ax = fig.add_subplot(gs[0, 1])\n",
    "        plt.colorbar(aximg, cax=ax)\n",
    "        plt.tight_layout()\n",
    "        plt.show(fig)\n",
    "        \n",
    "    return get_slice_3D\n",
    "    \n",
    "def islicer(data, direction, title=\"\", cmap='viridis', minmax=None):\n",
    "    '''Creates an interactive integer slider that slices a 3D volume along direction\n",
    "    \n",
    "    :param data: DataContainer or numpy array\n",
    "    :param direction: slice direction, int, should be 0,1,2 or the axis label\n",
    "    :param title: optional title for the display\n",
    "    '''\n",
    "    \n",
    "    if hasattr(data, \"as_array\"):\n",
    "        container = data.as_array()\n",
    "        if not isinstance (direction, int):\n",
    "            if direction in data.dimension_labels.values():\n",
    "                direction = data.get_dimension_axis(direction)\n",
    "    elif isinstance (data, numpy.ndarray):\n",
    "        container = data\n",
    "        \n",
    "    \n",
    "    slider = widgets.IntSlider(min=0, max=data.shape[direction]-1, step=1, \n",
    "                             value=0, continuous_update=False)\n",
    "\n",
    "    if minmax is None:\n",
    "        amax = container.max()\n",
    "        amin = container.min()\n",
    "    else:\n",
    "        amin = min(minmax)\n",
    "        amax = max(minmax)\n",
    "    \n",
    "    interact(display_slice(container, \n",
    "                           direction, \n",
    "                           title=title, \n",
    "                           cmap=cmap, \n",
    "                           minmax=(amin, amax)),\n",
    "             x=slider);\n",
    "    return slider\n",
    "    \n",
    "\n",
    "def link_islicer(*args):\n",
    "    '''links islicers IntSlider widgets'''\n",
    "    linked = [(widg, 'value') for widg in args]\n",
    "    # link pair-wise\n",
    "    pairs = [(linked[i+1],linked[i]) for i in range(len(linked)-1)]\n",
    "    for pair in pairs:\n",
    "        widgets.link(*pair)\n",
    "    \n",
    "islicer(algo.get_output().as_array(), 1, \"PDHG iter {}\".format(algo.iteration), cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0, 50.]\n",
    "gs = [IndicatorBox(lower=0.), FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' )]\n",
    "for alpha, g in zip(alphas, gs):\n",
    "    print (alpha, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset algo and run 500 iterations\n",
    "# it should take 86.107 s/iter * 500 iter / 3600 s/h = 11.9 h\n",
    "alphas = [0, 50.]\n",
    "gs = [IndicatorBox(lower=0.), FGP_TV(alpha, 500, 1e-7, 0, 1, 0, 'gpu' )]\n",
    "for alpha, g in zip(alphas, gs):\n",
    "    algo = PDHG(f = fidelity, g = g, operator = operator, tau = tau, sigma = sigma)\n",
    "    algo.max_iteration = 500\n",
    "    algo.update_objective_interval = 10\n",
    "\n",
    "    if False:\n",
    "        run = 10\n",
    "        for i in range(algo.max_iteration / run):\n",
    "            algo.run(run)\n",
    "            # saves to os.getcwd()\n",
    "            #print (os.getcwd())\n",
    "            fname = os.path.join(os.getcwd(),\"PDHG_FGP_alpha{}_iter_{}\".format(alpha,algo.iteration))\n",
    "            algo.get_output().write(fname)\n",
    "    else:\n",
    "        def save_output(iteration,obj,x):\n",
    "            alpha = 0\n",
    "            fname = os.path.join(os.getcwd(),\"PDHG_FGP_alpha{}_iter_{}\".format(alpha,iteration))\n",
    "            x.write(fname)\n",
    "\n",
    "        algo.run(500,callback=save_output,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(os.getcwd(),\"PDHG_FGP_alpha{}_iter_{}\".format(alpha,algo.iteration))\n",
    "print (os.getcwd(), alpha, fname)\n",
    "algo.get_output().write(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ccpi.io import NEXUSReader\n",
    "fname = os.path.join(os.getcwd(),\"PDHG_FGP_alpha{}_iter_{}\".format(alpha,100))\n",
    "read = NEXUSReader()\n",
    "read.set_up(nexus_file=fname)\n",
    "read.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s1 = islicer(algo.get_output().as_array(), 0, \"PDHG iter {}\".format(algo.iteration))\n",
    "s0 = islicer(solution_4.as_array(), 0, \"PDHG iter {}\".format(4))\n",
    "\n",
    "link_islicer(s1,s0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves to os.getcwd()\n",
    "#print (os.getcwd())\n",
    "\n",
    "\n",
    "algo.get_output().write(\"PDHG_FGP_alpha{}_iter_{}\".format(alpha,algo.iteration))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
